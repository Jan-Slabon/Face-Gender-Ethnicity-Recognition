{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692c3a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849ed0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03e53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data have been already cleaned and process please read \"cleaned_data.csv\" instead of \"age_gender.csv\"\n",
    "data_set = pd.read_csv(\"age_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e09dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pixels = data_set[\"pixels\"].str.split(' ', expand = True)\n",
    "data_set.drop(\"img_name\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109743d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([data_set, split_pixels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f544251",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pixels = split_pixels.apply(pd.to_numeric, args = ('ignore', 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6c276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.572549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.631373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.505882  0.501961  0.501961  0.494118  0.498039  0.509804  0.521569   \n",
       "1  0.643137  0.290196  0.435294  0.658824  0.662745  0.670588  0.686275   \n",
       "2  0.262745  0.274510  0.278431  0.274510  0.270588  0.262745  0.274510   \n",
       "3  0.756863  0.772549  0.776471  0.784314  0.780392  0.784314  0.792157   \n",
       "4  0.792157  0.803922  0.819608  0.823529  0.819608  0.819608  0.823529   \n",
       "\n",
       "       7         8         9     ...      2294      2295      2296      2297  \\\n",
       "0  0.529412  0.545098  0.556863  ...  0.482353  0.505882  0.525490  0.541176   \n",
       "1  0.713726  0.721569  0.737255  ...  0.658824  0.741176  0.874510  0.945098   \n",
       "2  0.309804  0.352941  0.403922  ...  0.458824  0.443137  0.454902  0.454902   \n",
       "3  0.796078  0.800000  0.803922  ...  0.854902  0.870588  0.890196  0.894118   \n",
       "4  0.827451  0.831373  0.839216  ...  0.647059  0.654902  0.654902  0.654902   \n",
       "\n",
       "       2298      2299      2300      2301      2302      2303  \n",
       "0  0.556863  0.564706  0.564706  0.572549  0.572549  0.572549  \n",
       "1  0.925490  0.909804  0.800000  0.713726  0.666667  0.580392  \n",
       "2  0.458824  0.458824  0.450980  0.439216  0.435294  0.423529  \n",
       "3  0.894118  0.901961  0.905882  0.921569  0.937255  0.964706  \n",
       "4  0.658824  0.670588  0.670588  0.654902  0.639216  0.631373  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pom = split_pixels / 255\n",
    "pom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce59aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([data_set, pom], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497b6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"cleaned_data.csv\")\n",
    "#end of cleaning portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db53a8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.572549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.631373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender         0         1         2         3         4         5  \\\n",
       "0       0  0.505882  0.501961  0.501961  0.494118  0.498039  0.509804   \n",
       "1       0  0.643137  0.290196  0.435294  0.658824  0.662745  0.670588   \n",
       "2       0  0.262745  0.274510  0.278431  0.274510  0.270588  0.262745   \n",
       "3       0  0.756863  0.772549  0.776471  0.784314  0.780392  0.784314   \n",
       "4       0  0.792157  0.803922  0.819608  0.823529  0.819608  0.819608   \n",
       "\n",
       "          6         7         8  ...      2294      2295      2296      2297  \\\n",
       "0  0.521569  0.529412  0.545098  ...  0.482353  0.505882  0.525490  0.541176   \n",
       "1  0.686275  0.713726  0.721569  ...  0.658824  0.741176  0.874510  0.945098   \n",
       "2  0.274510  0.309804  0.352941  ...  0.458824  0.443137  0.454902  0.454902   \n",
       "3  0.792157  0.796078  0.800000  ...  0.854902  0.870588  0.890196  0.894118   \n",
       "4  0.823529  0.827451  0.831373  ...  0.647059  0.654902  0.654902  0.654902   \n",
       "\n",
       "       2298      2299      2300      2301      2302      2303  \n",
       "0  0.556863  0.564706  0.564706  0.572549  0.572549  0.572549  \n",
       "1  0.925490  0.909804  0.800000  0.713726  0.666667  0.580392  \n",
       "2  0.458824  0.458824  0.450980  0.439216  0.435294  0.423529  \n",
       "3  0.894118  0.901961  0.905882  0.921569  0.937255  0.964706  \n",
       "4  0.658824  0.670588  0.670588  0.654902  0.639216  0.631373  \n",
       "\n",
       "[5 rows x 2305 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start here\n",
    "data_set = pd.read_csv(\"cleaned_data.csv\")\n",
    "data_set.drop(\"age\",axis=1,inplace=True) ; data_set.drop(\"ethnicity\",axis=1,inplace=True) ; data_set.drop(\"pixels\",axis=1,inplace=True)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c89dd73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23705, 2305)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8331bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_working_set = data_set.sample(frac = 0.3)\n",
    "train = Model_working_set.sample(frac = 0.8)\n",
    "test = Model_working_set.drop(train.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f15eee32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_05_31-18_57_32'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a82e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045045d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "720bed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"gender\", axis = 1)\n",
    "y_train = train.gender\n",
    "X_test = test.drop(\"gender\", axis = 1)\n",
    "y_test = test.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eddec7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4f66e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "062aca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa681a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2500, activation = \"sigmoid\", input_shape =(X_train.shape[1], )))\n",
    "model.add(Dense(1000, activation = \"elu\" ))\n",
    "model.add(Dense(500, activation = \"elu\" ))\n",
    "model.add(Dense(100, activation = \"elu\" ))\n",
    "model.add(Dense(10, activation = \"elu\" ))\n",
    "model.add(Dense(1, activation = \"sigmoid\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee923647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f75a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "178/178 [==============================] - 384s 119ms/step - loss: 0.7384 - accuracy: 0.5870 - val_loss: 0.5672 - val_accuracy: 0.7328\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.5561 - accuracy: 0.7237 - val_loss: 0.4966 - val_accuracy: 0.7932\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.5035 - accuracy: 0.7685 - val_loss: 0.4635 - val_accuracy: 0.7911\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 18s 102ms/step - loss: 0.4457 - accuracy: 0.7949 - val_loss: 0.4331 - val_accuracy: 0.8186\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 19s 105ms/step - loss: 0.4361 - accuracy: 0.7963 - val_loss: 0.4217 - val_accuracy: 0.8087\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.3900 - accuracy: 0.8236 - val_loss: 0.4097 - val_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.3881 - accuracy: 0.8218 - val_loss: 0.5499 - val_accuracy: 0.7293\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.3845 - accuracy: 0.8232 - val_loss: 0.3740 - val_accuracy: 0.8376\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 18s 102ms/step - loss: 0.3822 - accuracy: 0.8153 - val_loss: 0.4800 - val_accuracy: 0.7890\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.3739 - accuracy: 0.8227 - val_loss: 0.4013 - val_accuracy: 0.8305\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3859 - accuracy: 0.8176 - val_loss: 0.3770 - val_accuracy: 0.8312\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.3553 - accuracy: 0.8327 - val_loss: 0.3739 - val_accuracy: 0.8354\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3828 - accuracy: 0.8211 - val_loss: 0.4866 - val_accuracy: 0.7651\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 18s 102ms/step - loss: 0.3390 - accuracy: 0.8452 - val_loss: 0.4122 - val_accuracy: 0.8256\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3431 - accuracy: 0.8409 - val_loss: 0.3893 - val_accuracy: 0.8291\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3337 - accuracy: 0.8415 - val_loss: 0.3730 - val_accuracy: 0.8411\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3235 - accuracy: 0.8497 - val_loss: 0.3583 - val_accuracy: 0.8361\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3326 - accuracy: 0.8429 - val_loss: 0.3926 - val_accuracy: 0.8150\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3323 - accuracy: 0.8443 - val_loss: 0.3712 - val_accuracy: 0.8453\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3358 - accuracy: 0.8424 - val_loss: 0.3791 - val_accuracy: 0.8432\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3421 - accuracy: 0.8476 - val_loss: 0.4175 - val_accuracy: 0.8207\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3147 - accuracy: 0.8587 - val_loss: 0.3688 - val_accuracy: 0.8453\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.3137 - accuracy: 0.8538 - val_loss: 0.3555 - val_accuracy: 0.8411\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3287 - accuracy: 0.8480 - val_loss: 0.3495 - val_accuracy: 0.8488\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3072 - accuracy: 0.8613 - val_loss: 0.3876 - val_accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.3198 - accuracy: 0.8489 - val_loss: 0.3621 - val_accuracy: 0.8418\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.3094 - accuracy: 0.8585 - val_loss: 0.4044 - val_accuracy: 0.8270\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2989 - accuracy: 0.8582 - val_loss: 0.3710 - val_accuracy: 0.8439\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.3006 - accuracy: 0.8645 - val_loss: 0.3757 - val_accuracy: 0.8495\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2955 - accuracy: 0.8657 - val_loss: 0.3663 - val_accuracy: 0.8432\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - 18s 102ms/step - loss: 0.3164 - accuracy: 0.8562 - val_loss: 0.3611 - val_accuracy: 0.8383\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2952 - accuracy: 0.8670 - val_loss: 0.4052 - val_accuracy: 0.8460\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - 19s 108ms/step - loss: 0.2882 - accuracy: 0.8705 - val_loss: 0.3691 - val_accuracy: 0.8446\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.3129 - accuracy: 0.8543 - val_loss: 0.3915 - val_accuracy: 0.8502\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - 18s 98ms/step - loss: 0.2814 - accuracy: 0.8763 - val_loss: 0.3590 - val_accuracy: 0.8432\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2930 - accuracy: 0.8692 - val_loss: 0.3810 - val_accuracy: 0.8530\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2881 - accuracy: 0.8724 - val_loss: 0.3909 - val_accuracy: 0.8411\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.3051 - accuracy: 0.8599 - val_loss: 0.3876 - val_accuracy: 0.8228\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2749 - accuracy: 0.8749 - val_loss: 0.3565 - val_accuracy: 0.8390\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2832 - accuracy: 0.8721 - val_loss: 0.3919 - val_accuracy: 0.8411\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2776 - accuracy: 0.8764 - val_loss: 0.3656 - val_accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2797 - accuracy: 0.8736 - val_loss: 0.3747 - val_accuracy: 0.8277\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - 18s 103ms/step - loss: 0.2940 - accuracy: 0.8645 - val_loss: 0.4957 - val_accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - 19s 107ms/step - loss: 0.2805 - accuracy: 0.8750 - val_loss: 0.3687 - val_accuracy: 0.8488\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2684 - accuracy: 0.8766 - val_loss: 0.4032 - val_accuracy: 0.8368\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.2543 - accuracy: 0.8907 - val_loss: 0.4171 - val_accuracy: 0.8537\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.2681 - accuracy: 0.8789 - val_loss: 0.4725 - val_accuracy: 0.7961\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2731 - accuracy: 0.8789 - val_loss: 0.3546 - val_accuracy: 0.8460\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.2540 - accuracy: 0.8838 - val_loss: 0.5298 - val_accuracy: 0.7700\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2502 - accuracy: 0.8854 - val_loss: 0.3661 - val_accuracy: 0.8432\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2559 - accuracy: 0.8845 - val_loss: 0.3922 - val_accuracy: 0.8453\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2483 - accuracy: 0.8895 - val_loss: 0.3774 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2503 - accuracy: 0.8833 - val_loss: 0.8690 - val_accuracy: 0.7644\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2750 - accuracy: 0.8749 - val_loss: 0.3947 - val_accuracy: 0.8453\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2617 - accuracy: 0.8840 - val_loss: 0.3884 - val_accuracy: 0.8404\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.2628 - accuracy: 0.8822 - val_loss: 0.4045 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 18s 104ms/step - loss: 0.2684 - accuracy: 0.8770 - val_loss: 0.4027 - val_accuracy: 0.8284\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.2534 - accuracy: 0.8835 - val_loss: 0.3786 - val_accuracy: 0.8495\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.2571 - accuracy: 0.8842 - val_loss: 0.4366 - val_accuracy: 0.7897\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.2575 - accuracy: 0.8800 - val_loss: 0.3601 - val_accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.2320 - accuracy: 0.8965 - val_loss: 0.4062 - val_accuracy: 0.8453\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2575 - accuracy: 0.8819 - val_loss: 0.3725 - val_accuracy: 0.8368\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - 18s 103ms/step - loss: 0.2411 - accuracy: 0.8900 - val_loss: 0.3556 - val_accuracy: 0.8502\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2438 - accuracy: 0.8888 - val_loss: 0.3976 - val_accuracy: 0.8488\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2501 - accuracy: 0.8858 - val_loss: 0.4173 - val_accuracy: 0.8439\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2243 - accuracy: 0.9051 - val_loss: 0.3855 - val_accuracy: 0.8404\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2478 - accuracy: 0.8893 - val_loss: 0.3943 - val_accuracy: 0.8376\n",
      "Epoch 68/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2280 - accuracy: 0.8982 - val_loss: 0.4272 - val_accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2354 - accuracy: 0.8944 - val_loss: 0.4029 - val_accuracy: 0.8376\n",
      "Epoch 70/100\n",
      "178/178 [==============================] - 18s 98ms/step - loss: 0.2514 - accuracy: 0.8854 - val_loss: 0.3763 - val_accuracy: 0.8453\n",
      "Epoch 71/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.2252 - accuracy: 0.9002 - val_loss: 0.4026 - val_accuracy: 0.8249\n",
      "Epoch 72/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2345 - accuracy: 0.8931 - val_loss: 0.3700 - val_accuracy: 0.8354\n",
      "Epoch 73/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2309 - accuracy: 0.8970 - val_loss: 0.4028 - val_accuracy: 0.8108\n",
      "Epoch 74/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.2449 - accuracy: 0.8840 - val_loss: 0.4405 - val_accuracy: 0.8200\n",
      "Epoch 75/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2536 - accuracy: 0.8856 - val_loss: 0.3969 - val_accuracy: 0.8425\n",
      "Epoch 76/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2198 - accuracy: 0.9030 - val_loss: 0.4067 - val_accuracy: 0.8354\n",
      "Epoch 77/100\n",
      "178/178 [==============================] - 19s 104ms/step - loss: 0.2262 - accuracy: 0.8982 - val_loss: 0.4130 - val_accuracy: 0.8453\n",
      "Epoch 78/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.2208 - accuracy: 0.9058 - val_loss: 0.4112 - val_accuracy: 0.8411\n",
      "Epoch 79/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2144 - accuracy: 0.9025 - val_loss: 0.4370 - val_accuracy: 0.8397\n",
      "Epoch 80/100\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.2280 - accuracy: 0.8972 - val_loss: 0.4885 - val_accuracy: 0.8235\n",
      "Epoch 81/100\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.2296 - accuracy: 0.8967 - val_loss: 0.4374 - val_accuracy: 0.8467\n",
      "Epoch 82/100\n",
      "178/178 [==============================] - 18s 103ms/step - loss: 0.2433 - accuracy: 0.8902 - val_loss: 0.4091 - val_accuracy: 0.8460\n",
      "Epoch 83/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2215 - accuracy: 0.8988 - val_loss: 0.3948 - val_accuracy: 0.8397\n",
      "Epoch 84/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2144 - accuracy: 0.9065 - val_loss: 0.4705 - val_accuracy: 0.8340\n",
      "Epoch 85/100\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 0.2065 - accuracy: 0.9116 - val_loss: 0.4299 - val_accuracy: 0.8495\n",
      "Epoch 86/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2200 - accuracy: 0.8993 - val_loss: 0.4041 - val_accuracy: 0.8425\n",
      "Epoch 87/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2067 - accuracy: 0.9114 - val_loss: 0.5055 - val_accuracy: 0.7954\n",
      "Epoch 88/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2131 - accuracy: 0.9104 - val_loss: 0.4178 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1895 - accuracy: 0.9158 - val_loss: 0.4432 - val_accuracy: 0.8368\n",
      "Epoch 90/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.1974 - accuracy: 0.9125 - val_loss: 0.4922 - val_accuracy: 0.8488\n",
      "Epoch 91/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.1953 - accuracy: 0.9165 - val_loss: 0.6131 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.1972 - accuracy: 0.9146 - val_loss: 0.4286 - val_accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2101 - accuracy: 0.9109 - val_loss: 0.4309 - val_accuracy: 0.8319\n",
      "Epoch 94/100\n",
      "178/178 [==============================] - 18s 98ms/step - loss: 0.2168 - accuracy: 0.9065 - val_loss: 0.4223 - val_accuracy: 0.8474\n",
      "Epoch 95/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2015 - accuracy: 0.9149 - val_loss: 0.4365 - val_accuracy: 0.8256\n",
      "Epoch 96/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2045 - accuracy: 0.9074 - val_loss: 0.3838 - val_accuracy: 0.8460\n",
      "Epoch 97/100\n",
      "178/178 [==============================] - 18s 100ms/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 0.3794 - val_accuracy: 0.8446\n",
      "Epoch 98/100\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.2028 - accuracy: 0.9090 - val_loss: 0.4348 - val_accuracy: 0.8453\n",
      "Epoch 99/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.2006 - accuracy: 0.9149 - val_loss: 0.4128 - val_accuracy: 0.8397\n",
      "Epoch 100/100\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.1968 - accuracy: 0.9116 - val_loss: 0.4051 - val_accuracy: 0.8488\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1a34360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models/1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./trained_models/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67098945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
